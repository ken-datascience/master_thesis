{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt #描画ライブラリ\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "import pathlib\n",
    "import glob\n",
    "import math\n",
    "import codecs\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total demand & Generation by different type of plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the common path where dataset put\n",
    "path ='/Users/kenotsu/Documents/master_thesis/Datasets/Master_thesis/actual_generation_demand'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tohoku (base)\n",
    "# Search file path on the folder using wildcard\n",
    "allFiles = sorted(glob.glob(path + \"/Tohoku/juyo_*.csv\")) \n",
    "frame = pd.DataFrame()\n",
    "col_names = [\"DateTime\", \"TotalDemand_TOH\", \"Water_TOH\", \"Thermal_TOH\", \"Nuclear_TOH\", \"PV_TOH\", \n",
    "             \"PVCurtailment_TOH\", \"Wind_TOH\", \"WindCurtailment_TOH\", \"Geothermal_TOH\", \"Biomass_TOH\", \n",
    "             \"PumpedStorage_TOH\", \"Interconnection_TOH\"]\n",
    "list_ = []\n",
    "for file_path in allFiles:\n",
    "    # It has original columns. Do not set new name of columns\n",
    "    df = pd.read_csv(file_path, sep=',', header=0, delimiter=\",\", names=col_names, encoding='shift_jis') \n",
    "    list_.append(df)\n",
    "frame = pd.concat(list_, join='inner').reset_index()\n",
    "frame = frame.drop(\"index\", axis=1)\n",
    "\n",
    "# Base index\n",
    "DateTime_Tohoku = frame[\"DateTime\"]\n",
    "\n",
    "frame.to_csv(path + \"/Demand_plant_tohoku.csv\", encoding=\"shift_jis\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hokkaido\n",
    "# Search file path on the folder using wildcard\n",
    "allFiles = sorted(glob.glob(path + \"/Hokkaido/sup_dem_results_*.csv\")) \n",
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "# Set the original common columns\n",
    "col_names = [\"Date\", \"Time\", \"TotalDemand_HOK\", \"Nuclear_HOK\", \"Thermal_HOK\", \"Water_HOK\", \"Geothermal_HOK\", \"Biomass_HOK\", \"PV_HOK\", \n",
    "             \"PVCurtailment_HOK\", \"Wind_HOK\", \"WindCurtailment_HOK\", \"PumpedStorage_HOK\", \"Interconnection_HOK\", \"TotalSupply_HOK\"]\n",
    "# Read the files\n",
    "for file_path in allFiles:\n",
    "    # Avoiding UnicodeDecodeError\n",
    "    with codecs.open(file_path, \"r\", \"shift_jis\", \"ignore\") as file_:\n",
    "        # Read csv\n",
    "        df = pd.read_csv(file_, delimiter=\",\", names=col_names, skiprows=[0,1,2,3]) \n",
    "#         df = df.dropna(how='all', axis=0)\n",
    "        list_.append(df)\n",
    "# Concat all the csv file on the folder\n",
    "frame = pd.concat(list_, join='inner')\n",
    "frame = frame.dropna(how='all', axis=0).reset_index()\n",
    "frame = frame.drop(\"index\", axis=1)\n",
    "\n",
    "# Adjust DateTime column\n",
    "frame[\"DateTime\"] = DateTime_Tohoku\n",
    "frame = frame.drop([\"Date\", \"Time\"], axis=1)\n",
    "\n",
    "frame.to_csv(path + \"/Demand_plant_Hokkaido.csv\", encoding=\"shift_jis\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokyo\n",
    "# Search file path on the folder using wildcard\n",
    "allFiles = sorted(glob.glob(path + \"/Tokyo/area-*.csv\"))\n",
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "# Set the original common columns\n",
    "col_names = [\"Date\", \"Time\", \"TotalDemand_TKO\", \"Nuclear_TKO\", \"Thermal_TKO\", \"Water_TKO\", \"Geothermal_TKO\", \"Biomass_TKO\", \"PV_TKO\",\n",
    "             \"PVCurtailment_TKO\", \"Wind_TKO\", \"WindCurtailment_TKO\", \"PumpedStorage_TKO\", \"Interconnection_TKO\", \"TotalSupply_TKO\"]\n",
    "# Read the files\n",
    "for file_path in allFiles:\n",
    "    # Avoiding UnicodeDecodeError\n",
    "    with codecs.open(file_path, \"r\", \"Shift-JIS\", \"ignore\") as file_:\n",
    "        # Read csv\n",
    "        df = pd.read_csv(file_, delimiter=\",\", names=col_names, skiprows=[0,1,2])\n",
    "        list_.append(df)\n",
    "# Concat all the csv file on the folder\n",
    "frame = pd.concat(list_, join='inner').reset_index()\n",
    "frame = frame.drop(\"index\", axis=1)\n",
    "frame = frame[0:41664]\n",
    "\n",
    "# Adjust DateTime column\n",
    "frame[\"DateTime\"] = DateTime_Tohoku\n",
    "frame = frame.drop([\"Date\", \"Time\"], axis=1)\n",
    "\n",
    "frame.to_csv(path + \"/Demand_plant_Tokyo.csv\", encoding=\"shift_jis\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chubu\n",
    "# Search file path on the folder using wildcard\n",
    "allFiles = sorted(glob.glob(path + \"/Chubu/areabalance_current_term_*.csv\")) \n",
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "# Set the original common columns\n",
    "col_names = [\"Date\", \"Time\", \"TotalDemand_CHB\", \"Nuclear_CHB\", \"Thermal_CHB\", \"Water_CHB\", \"Geothermal_CHB\", \"Biomass_CHB\", \"PV_CHB\", \n",
    "             \"PVCurtailment_CHB\", \"Wind_CHB\", \"WindCurtailment_CHB\",\"PumpedStorage_CHB\", \"Interconnection_CHB\"]\n",
    "# Read the files\n",
    "for file_path in allFiles:\n",
    "    # Avoiding UnicodeDecodeError\n",
    "    with codecs.open(file_path, \"r\", \"Shift-JIS\", \"ignore\") as file_:\n",
    "        # Read csv\n",
    "        df = pd.read_csv(file_, header=0, delimiter=\",\", names=col_names, skiprows=[0,1,2,3])\n",
    "        list_.append(df)\n",
    "# Concat all the csv file on the folder\n",
    "frame = pd.concat(list_, join='inner').reset_index()\n",
    "frame = frame.drop(\"index\", axis=1)\n",
    "frame = frame[0:41664]\n",
    "\n",
    "# Adjust DateTime column\n",
    "frame[\"DateTime\"] = DateTime_Tohoku\n",
    "frame = frame.drop([\"Date\", \"Time\"], axis=1)\n",
    "\n",
    "frame.to_csv(path + \"/Demand_plant_Chubu.csv\", encoding=\"shift_jis\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hokuriku\n",
    "# Search file path on the folder using wildcard\n",
    "allFiles = sorted(glob.glob(path + \"/Hokuriku/area_jisseki_rikuden*.csv\"))\n",
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "# Set the original common columns\n",
    "col_names = [\"Date\", \"Time\", \"TotalDemand_HKU\", \"Nuclear_HKU\", \"Thermal_HKU\", \"Water_HKU\", \"Geothermal_HKU\", \"Biomass_HKU\", \"PV_HKU\", \n",
    "             \"PVCurtailment_HKU\", \"Wind_HKU\", \"WindCurtailment_HKU\",\"PumpedStorage_HKU\", \"Interconnection_HKU\"]\n",
    "# Read the files\n",
    "for file_path in allFiles:\n",
    "    # Avoiding UnicodeDecodeError\n",
    "    with codecs.open(file_path, \"r\", \"Shift-JIS\", \"ignore\") as file_:\n",
    "        # Read csv\n",
    "        df = pd.read_csv(file_, header=0, delimiter=\",\", names=col_names, skiprows=[0,1,2,3,4], usecols=[0,1,2,3,4,5,6,7,8,9,10,11,12,13])\n",
    "        list_.append(df)\n",
    "# Concat all the csv file on the folder\n",
    "frame = pd.concat(list_, join='inner')\n",
    "frame = frame.dropna(how='all', axis=0)\n",
    "# delete row contains \"TIME\" in TIme column\n",
    "frame = frame[~frame['Time'].str.contains('TIME')].reset_index()\n",
    "frame = frame.drop(\"index\", axis=1)\n",
    "frame = frame[0:41664]\n",
    "\n",
    "# Adjust DateTime column\n",
    "frame[\"DateTime\"] = DateTime_Tohoku\n",
    "frame = frame.drop([\"Date\", \"Time\"], axis=1)\n",
    "\n",
    "frame.to_csv(path + \"/Demand_plant_Hokuriku.csv\", encoding=\"shift_jis\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kansai\n",
    "# Search file path on the folder using wildcard\n",
    "allFiles = sorted(glob.glob(path + \"/Kansai/area_jyukyu_jisseki_*.csv\")) \n",
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "# Set the original common columns\n",
    "col_names = [\"DateTime\", \"TotalDemand_KAN\", \"Nuclear_KAN\", \"Thermal_KAN\", \"Water_KAN\", \"Geothermal_KAN\", \"Biomass_KAN\", \"PV_KAN\", \n",
    "             \"PVCurtailment_KAN\", \"Wind_KAN\", \"WindCurtailment_KAN\",\"PumpedStorage_KAN\", \"Interconnection_KAN\"]\n",
    "# Read the files\n",
    "for file_path in allFiles:\n",
    "    # Avoiding UnicodeDecodeError\n",
    "    with codecs.open(file_path, \"r\", \"Shift-JIS\", \"ignore\") as file_:\n",
    "        # Read csv\n",
    "        df = pd.read_csv(file_, header=0, delimiter=\",\", names=col_names, skiprows=[0])\n",
    "        list_.append(df)\n",
    "# Concat all the csv file on the folder\n",
    "frame = pd.concat(list_, join='inner')\n",
    "frame = frame.dropna(how='all', axis=0).reset_index()\n",
    "frame = frame.drop(\"index\", axis=1)\n",
    "frame = frame[0:41664]\n",
    "\n",
    "# Adjust DateTime column\n",
    "frame[\"DateTime\"] = DateTime_Tohoku\n",
    "frame.to_csv(path + \"/Demand_plant_Kansai.csv\", encoding=\"shift_jis\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chugoku\n",
    "file_path = \"/Users/kenotsu/Documents/master_thesis/Datasets/Master_thesis/actual_generation_demand/Chugoku/eria_jyukyu.csv\"\n",
    "\n",
    "# Set the original common columns\n",
    "col_names = [\"Date\", \"Time\", \"TotalDemand_CHG\", \"Nuclear_CHG\", \"Thermal_CHG\", \"Water_CHG\", \"Geothermal_CHG\", \"Biomass_CHG\", \"PV_CHG\", \n",
    "             \"PVCurtailment_CHG\", \"Wind_CHG\", \"WindCurtailment_CHG\",\"PumpedStorage_CHG\", \"Interconnection_CHG\"]\n",
    "\n",
    "# Avoiding UnicodeDecodeError\n",
    "with codecs.open(file_path, \"r\", \"Shift-JIS\", \"ignore\") as file_:\n",
    "    # Read csv setting col_names\n",
    "    df = pd.read_csv(file_, header=0, delimiter=\",\", names=col_names, skiprows=[0,1])\n",
    "\n",
    "# reset index\n",
    "df = df.reset_index()\n",
    "df = df.drop(\"index\", axis=1)\n",
    "# Pick up until 12/31 23:00\n",
    "df = df[:25560]\n",
    "\n",
    "# Adjust DateTime column from 2018/2/1 0:00 to 12/31 23:00\n",
    "df[\"DateTime\"] = DateTime_Tohoku[16104:].reset_index().drop(\"index\", axis=1)\n",
    "df = df.drop([\"Date\", \"Time\"], axis=1)\n",
    "\n",
    "# Save csv\n",
    "df.to_csv(path + \"/Demand_plant_Chugoku.csv\", encoding=\"shift_jis\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shikoku\n",
    "# Search file path on the folder using wildcard\n",
    "allFiles = sorted(glob.glob(path + \"/Shikoku/jukyu*.csv\")) # 指定したフォルダーの全CSVファイルを変数に代入します\n",
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "# Set the original common columns\n",
    "col_names = [\"Date\", \"Time\", \"TotalDemand_SHI\", \"Nuclear_SHI\", \"Thermal_SHI\", \"Water_SHI\", \"Biomass_SHI\",  \"PV_SHI\", \n",
    "             \"PVCurtailment_SHI\", \"Wind_SHI\", \"WindCurtailment_SHI\",\"PumpedStorage_SHI\", \"Interconnection_SHI\", \"TotalSupply_SHI\"]\n",
    "# Read the files\n",
    "for file_path in allFiles:\n",
    "    # Avoiding UnicodeDecodeError\n",
    "    with codecs.open(file_path, \"r\", \"Shift-JIS\", \"ignore\") as file_:\n",
    "        # Read csv skipping the last row which is blank\n",
    "        df = pd.read_csv(file_, header=0, delimiter=\",\", names=col_names, skiprows=[0,1,2,3,4,5,6,7], usecols=[0,1,2,3,4,5,7,8,9,10,11,12,13,14])\n",
    "        list_.append(df)\n",
    "# Concat all the csv file on the folder\n",
    "frame = pd.concat(list_, join='inner')\n",
    "frame = frame.dropna(how='all', axis=0).reset_index()\n",
    "frame = frame.drop(\"index\", axis=1)\n",
    "frame = frame[0:41664]\n",
    "\n",
    "# Adjust DateTime column\n",
    "frame[\"DateTime\"] = DateTime_Tohoku\n",
    "frame = frame.drop([\"Date\", \"Time\"], axis=1)\n",
    "frame.to_csv(path + \"/Demand_plant_Shikoku.csv\", encoding=\"shift_jis\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kyushu\n",
    "# Search file path on the folder using wildcard\n",
    "allFiles = sorted(glob.glob(path + \"/Kyushu/area_jyukyu_jisseki_*.csv\")) \n",
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "# Set the original common columns\n",
    "col_names = [\"DateTime\", \"TotalDemand_KYU\", \"Nuclear_KYU\", \"Thermal_KYU\", \"Water_KYU\", \"Geothermal_KYU\", \"Biomass_KYU\", \"PV_KYU\", \n",
    "             \"PVCurtailment_KYU\", \"Wind_KYU\", \"WindCurtailment_KYU\",\"PumpedStorage_KYU\", \"Interconnection_KYU\"]\n",
    "# Read the files\n",
    "for file_path in allFiles:\n",
    "    # Avoiding UnicodeDecodeError\n",
    "    with codecs.open(file_path, \"r\", \"Shift-JIS\", \"ignore\") as file_:\n",
    "        # Read csv\n",
    "        df = pd.read_csv(file_, header=0, delimiter=\",\", names=col_names, skiprows=[0])\n",
    "        list_.append(df)\n",
    "# Concat all the csv file on the folder\n",
    "frame = pd.concat(list_, join='inner')\n",
    "frame = frame.dropna(how='all', axis=0).reset_index()\n",
    "frame = frame.drop(\"index\", axis=1)\n",
    "\n",
    "# Adjust DateTime column\n",
    "frame[\"DateTime\"] = DateTime_Tohoku\n",
    "\n",
    "frame.to_csv(path + \"/Demand_plant_Kyushu.csv\", encoding=\"shift_jis\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okinawa\n",
    "# Search file path on the folder using wildcard\n",
    "allFiles = sorted(glob.glob(path + \"/Okinawa/*.csv\")) \n",
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "# Set the original common columns\n",
    "col_names = [\"Date\", \"Time\", \"TotalDemand_OKI\", \"Thermal_OKI\", \"Water_OKI\", \"Biomass_OKI\", \"PV_OKI\", \"PVCurtailment_OKI\", \n",
    "             \"Wind_OKI\", \"WindCurtailment_OKI\",\"TotalSupply_OKI\"]\n",
    "# Read the files\n",
    "for file_path in allFiles:\n",
    "    # Avoiding UnicodeDecodeError\n",
    "    with codecs.open(file_path, \"r\", \"Shift-JIS\", \"ignore\") as file_:\n",
    "        # Read csv\n",
    "        df = pd.read_csv(file_, header=0, delimiter=\",\", names=col_names, skiprows=[0,1,2,3,4,5], usecols=[0,1,2,4,5,6,7,8,9,10,11])\n",
    "        list_.append(df)\n",
    "# Concat all the csv file on the folder\n",
    "frame = pd.concat(list_, join='inner').reset_index()\n",
    "frame = frame.drop(\"index\", axis=1)\n",
    "frame = frame[0:41664]\n",
    "\n",
    "# Adjust DateTime column\n",
    "frame[\"DateTime\"] = DateTime_Tohoku\n",
    "# frame = frame.drop([\"Date\", \"Time\"], axis=1)\n",
    "frame.to_csv(path + \"/Demand_plant_Okinawa.csv\", encoding=\"shift_jis\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit_actual_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check list after integrating all the datasets of each area\n",
    "- The head and tail of the data (2016-04-01 - 2020-12-31)\n",
    "- The number of each half hourly time slot --> \"Date\" must have 48 time slots \"Time\" basically have 1735 time slots.\n",
    "- After checking above, the columns of \"DateTime\" must be inserted and that of \"Date\", \"Time\" are re-assigned from \"DateTime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/kenotsu/Documents/master_thesis/Datasets/Master_thesis/Fit_actual_prediction/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataTime column\n",
    "DateTime = pd.date_range('2016/04/01', periods=83328,  freq='30min').strftime('%Y/%m/%d %H:%M')\n",
    "DateTime = pd.Series(DateTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a table for QH_number\n",
    "df_intra_HH = df_intra.reset_index()\n",
    "HH_table = pd.DataFrame(df_intra_HH[\"HH\"])\n",
    "HH_table = HH_table.drop_duplicates()\n",
    "HH_table['Time'] = pd.date_range('2020/01/01', periods=48,  freq='30min').strftime('%H:%M')\n",
    "HH_table['Time'] = pd.to_datetime(HH_table['Time']).dt.time\n",
    "\n",
    "HH_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_=[]\n",
    "frame = pd.DataFrame()\n",
    "area = \"Hokkaido\"\n",
    "\n",
    "# Set the original common columns\n",
    "col_names = [\"Date\", \"Time\", \"ForecastPV_\"+area, \"ForecastWind_\"+area]\n",
    "# for file_path in allFiles:\n",
    "allFiles = sorted(glob.glob(path + area + \"/expect_*.csv\")) \n",
    "\n",
    "for file_path in allFiles:\n",
    "    # Read csv\n",
    "    df = pd.read_csv(file_path, header=0, delimiter=\",\", names=col_names, skiprows=[0, 1], usecols=[0,1,3,4])\n",
    "    list_.append(df)\n",
    "    \n",
    "# Concat all the csv file on the folder\n",
    "frame = pd.concat(list_, join='inner').reset_index(drop=True)\n",
    "\n",
    "# Adjust \"DataTime\"\n",
    "frame[\"DateTime\"] = DateTime[DateTime >= \"2020/01/01 00:00\"].reset_index(drop=True)\n",
    "frame[\"Date\"] = pd.to_datetime(frame[\"DateTime\"]).dt.date\n",
    "frame[\"Time\"] = pd.to_datetime(frame[\"DateTime\"]).dt.time\n",
    "frame = frame.drop([\"DateTime\"], axis=1)\n",
    "\n",
    "frame.to_csv(path + \"/FITforecast_\" + area + \".csv\", encoding=\"shift_jis\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>ForecastPV_Hokkaido</th>\n",
       "      <th>ForecastWind_Hokkaido</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>249.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>00:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>258.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>01:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>258.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>257.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time  ForecastPV_Hokkaido  ForecastWind_Hokkaido\n",
       "0  2020-01-01  00:00:00                  0.0                  249.6\n",
       "1  2020-01-01  00:30:00                  0.0                  256.4\n",
       "2  2020-01-01  01:00:00                  0.0                  258.4\n",
       "3  2020-01-01  01:30:00                  0.0                  258.6\n",
       "4  2020-01-01  02:00:00                  0.0                  257.0"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/kenotsu/Documents/master_thesis/Datasets/Master_thesis/Fit_actual_prediction/FITforecast_Hokkaido.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                     0\n",
       "Time                     0\n",
       "ForecastPV_Hokkaido      0\n",
       "ForecastWind_Hokkaido    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_=[]\n",
    "frame = pd.DataFrame()\n",
    "area = \"Tohoku\"\n",
    "\n",
    "# Set the original common columns\n",
    "col_names = [\"Date\", \"Time\", \"ForecastPV_\"+area, \"ForecastWind_\"+area]\n",
    "# for file_path in allFiles:\n",
    "allFiles = sorted(glob.glob(path + area + \"/*.csv\")) \n",
    "\n",
    "for file_path in allFiles:\n",
    "    # Read csv\n",
    "    df = pd.read_csv(file_path, header=0, delimiter=\",\", names=col_names, skiprows=[0,1], usecols=[0,1,4,6])\n",
    "    list_.append(df)\n",
    "    \n",
    "# Concat all the csv file on the folder\n",
    "frame = pd.concat(list_, join='inner').reset_index()\n",
    "frame = frame.drop(\"index\", axis=1)\n",
    "frame = frame[frame.index < 83328]\n",
    "frame = frame.fillna(0)\n",
    "\n",
    "# Adjust \n",
    "frame[\"DateTime\"] = DateTime[DateTime >= \"2016/04/01 00:00\"].reset_index(drop=True)\n",
    "frame[\"Date\"] = pd.to_datetime(frame[\"DateTime\"]).dt.date\n",
    "frame[\"Time\"] = pd.to_datetime(frame[\"DateTime\"]).dt.time\n",
    "frame = frame.drop([\"DateTime\"], axis=1)\n",
    "\n",
    "frame.to_csv(path + \"/FITforecast_\" + area + \".csv\", encoding=\"shift_jis\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>ForecastPV_Tohoku</th>\n",
       "      <th>ForecastWind_Tohoku</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>119,580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>00:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>119,580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>119,570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>01:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>119,590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>119,570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time ForecastPV_Tohoku ForecastWind_Tohoku\n",
       "0  2016-04-01  00:00:00                 0             119,580\n",
       "1  2016-04-01  00:30:00                 0             119,580\n",
       "2  2016-04-01  01:00:00                 0             119,570\n",
       "3  2016-04-01  01:30:00                 0             119,590\n",
       "4  2016-04-01  02:00:00                 0             119,570"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/kenotsu/Documents/master_thesis/Datasets/Master_thesis/Fit_actual_prediction/FITforecast_Tohoku.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                   0\n",
       "Time                   0\n",
       "ForecastPV_Tohoku      0\n",
       "ForecastWind_Tohoku    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_=[]\n",
    "frame = pd.DataFrame()\n",
    "area = \"Tokyo\"\n",
    "\n",
    "# Set the original common columns\n",
    "col_names = [\"Date\", \"Time\", \"ForecastPV_\"+area, \"ForecastWind_\"+area]\n",
    "# for file_path in allFiles:\n",
    "allFiles = sorted(glob.glob(path + area + \"/Tokyo_fit-*.csv\")) \n",
    "\n",
    "for file_path in allFiles:\n",
    "    # Read csv\n",
    "    df = pd.read_csv(file_path, header=0, delimiter=\",\", names=col_names, usecols=[0,1,3,5])\n",
    "    list_.append(df)\n",
    "    \n",
    "# Concat all the csv file on the folder\n",
    "frame = pd.concat(list_, join='inner').reset_index(drop=True)\n",
    "\n",
    "# Adjust \"DateTime\"\n",
    "frame[\"DateTime\"] = DateTime[DateTime >= \"2016/04/01 00:00\"].reset_index(drop=True)\n",
    "frame[\"Date\"] = pd.to_datetime(frame[\"DateTime\"]).dt.date\n",
    "frame[\"Time\"] = pd.to_datetime(frame[\"DateTime\"]).dt.time\n",
    "frame = frame.drop([\"DateTime\"], axis=1)\n",
    "\n",
    "frame.to_csv(path + \"/FITforecast_\" + area + \".csv\", encoding=\"shift_jis\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>ForecastPV_Tokyo</th>\n",
       "      <th>ForecastWind_Tokyo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>10,660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>00:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>10,888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>9,305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>01:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>11,027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>11,705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time ForecastPV_Tokyo ForecastWind_Tokyo\n",
       "0  2016-04-01  00:00:00                0             10,660\n",
       "1  2016-04-01  00:30:00                0             10,888\n",
       "2  2016-04-01  01:00:00                0              9,305\n",
       "3  2016-04-01  01:30:00                0             11,027\n",
       "4  2016-04-01  02:00:00                0             11,705"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/kenotsu/Documents/master_thesis/Datasets/Master_thesis/Fit_actual_prediction/FITforecast_Tokyo.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                  0\n",
       "Time                  0\n",
       "ForecastPV_Tokyo      0\n",
       "ForecastWind_Tokyo    0\n",
       "DateTime              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list=[]\n",
    "area = \"Chubu\"\n",
    "\n",
    "\n",
    "# for file_path in allFiles:\n",
    "allFiles = sorted(glob.glob(path + area + '/tokureihatsuden_*.xls')) \n",
    "\n",
    "# Read the sheat no.0 and 2 which are for the forecast information\n",
    "sheet_num = [0, 2]\n",
    "\n",
    "for file in allFiles:\n",
    "    for i in sheet_num:\n",
    "        df_sheet = pd.read_excel(file, sheet_name=i, skiprows=[0,1,2, 52], index_col=0)\n",
    "        # Add \"Time\" Column\n",
    "        df_sheet = df_sheet.reset_index(drop=True)\n",
    "        df_sheet[\"Time\"] = HH_time\n",
    "        df_sheet = df_sheet.set_index(\"Time\")\n",
    "       # Make the dataframe for PV and Wind separately, and organize the format\n",
    "        if i == 0:\n",
    "            df_sheet_0 = df_sheet.T\n",
    "            df_sheet_0 = pd.DataFrame(df_sheet_0.stack()).reset_index()\n",
    "            df_sheet_0 = df_sheet_0.rename(columns={'level_0': 'Date', 0:str(i)})\n",
    "        else:\n",
    "            df_sheet_2 = df_sheet.T\n",
    "            df_sheet_2 = pd.DataFrame(df_sheet_2.stack()).reset_index()\n",
    "            df_sheet_2 = df_sheet_2.rename(columns={'level_0': 'Date', 0:str(i)})        \n",
    "    # Concat all the sheet to make a file\n",
    "    df_file = pd.merge(df_sheet_0, df_sheet_2, how='left', on=['Date', 'Time'])\n",
    "    df_file = df_file.rename(columns={'0': 'Forecast_PV_Chubu', '2':'Forecast_Wind_Chubu'})\n",
    "    file_list.append(df_file)\n",
    "    \n",
    "# Merge all the csv file on the folder into a file\n",
    "frame = pd.concat(file_list, join='inner').reset_index(drop=True)\n",
    "\n",
    "# Adjust \"DateTime\"\n",
    "frame[\"DateTime\"] = DateTime[DateTime >= \"2016/04/01 00:00\"].reset_index(drop=True)\n",
    "frame[\"Date\"] = pd.to_datetime(frame[\"DateTime\"]).dt.date\n",
    "frame[\"Time\"] = pd.to_datetime(frame[\"DateTime\"]).dt.time\n",
    "frame = frame.drop([\"DateTime\"], axis=1)\n",
    "\n",
    "frame.to_csv(path + \"/FITforecast_\" + area + \".csv\", encoding=\"shift_jis\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Forecast_PV_Chubu</th>\n",
       "      <th>Forecast_Wind_Chubu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83323</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>21:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83324</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83325</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>22:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106476.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83326</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107466.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83327</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>23:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108352.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date      Time  Forecast_PV_Chubu  Forecast_Wind_Chubu\n",
       "83323  2020-12-31  21:30:00                0.0             104489.0\n",
       "83324  2020-12-31  22:00:00                0.0             105380.0\n",
       "83325  2020-12-31  22:30:00                0.0             106476.0\n",
       "83326  2020-12-31  23:00:00                0.0             107466.0\n",
       "83327  2020-12-31  23:30:00                0.0             108352.0"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/kenotsu/Documents/master_thesis/Datasets/Master_thesis/Fit_actual_prediction/FITforecast_Chubu.csv\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                   0\n",
       "Time                   0\n",
       "Forecast_PV_Chubu      0\n",
       "Forecast_Wind_Chubu    0\n",
       "DateTime               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_=[]\n",
    "frame = pd.DataFrame()\n",
    "area = \"Hokuriku\"\n",
    "\n",
    "# Set the original common columns\n",
    "col_names = [\"Date\", \"Time\", \"ForecastPV_\"+area, \"ForecastWind_\"+area]\n",
    "# for file_path in allFiles:\n",
    "allFiles = sorted(glob.glob(path + area + \"/fit1_rikuden*.csv\")) \n",
    "\n",
    "for file_path in allFiles:\n",
    "    # Read csv\n",
    "    df = pd.read_csv(file_path, header=0, delimiter=\",\", names=col_names, skiprows=[0], usecols=[0,1,3,5])\n",
    "    list_.append(df)\n",
    "    \n",
    "# Concat all the csv file on the folder\n",
    "frame = pd.concat(list_, join='inner')\n",
    "frame = frame.dropna(how='all').reset_index(drop=True)\n",
    "\n",
    "# Adjust \"DateTime\"\n",
    "frame[\"DateTime\"] = DateTime[DateTime >= \"2018/04/01 00:00\"].reset_index(drop=True)\n",
    "frame[\"Date\"] = pd.to_datetime(frame[\"DateTime\"]).dt.date\n",
    "frame[\"Time\"] = pd.to_datetime(frame[\"DateTime\"]).dt.time\n",
    "frame = frame.drop([\"DateTime\"], axis=1)\n",
    "\n",
    "frame.to_csv(path + \"/FITforecast_\" + area + \".csv\", encoding=\"shift_jis\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>ForecastPV_Hokuriku</th>\n",
       "      <th>ForecastWind_Hokuriku</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48283</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>21:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48284</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48285</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>22:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48286</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48287</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>23:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date      Time  ForecastPV_Hokuriku  ForecastWind_Hokuriku\n",
       "48283  2020-12-31  21:30:00                  0.0                27500.0\n",
       "48284  2020-12-31  22:00:00                  0.0                27000.0\n",
       "48285  2020-12-31  22:30:00                  0.0                29100.0\n",
       "48286  2020-12-31  23:00:00                  0.0                34700.0\n",
       "48287  2020-12-31  23:30:00                  0.0                40000.0"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/kenotsu/Documents/master_thesis/Datasets/Master_thesis/Fit_actual_prediction/FITforecast_Hokuriku.csv\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_=[]\n",
    "frame = pd.DataFrame()\n",
    "area = \"Kansai\"\n",
    "\n",
    "# Set the original common columns\n",
    "col_names = [\"DateTime\", \"ForecastPV_\"+area, \"ForecastWind_\"+area]\n",
    "# for file_path in allFiles:\n",
    "allFiles = sorted(glob.glob(path + area + \"/fit1_soutei_jisseki_*.csv\")) \n",
    "\n",
    "for file_path in allFiles:\n",
    "    # Read csv\n",
    "    df = pd.read_csv(file_path, header=0, delimiter=\",\", names=col_names, usecols=[0,1,3])\n",
    "    list_.append(df)\n",
    "    \n",
    "# Concat all the csv file on the folder\n",
    "frame = pd.concat(list_, join='inner').reset_index(drop=True)\n",
    "\n",
    "# Adjust \"DateTime\"\n",
    "frame[\"DateTime\"] = DateTime[DateTime >= \"2016/04/01 00:00\"].reset_index(drop=True)\n",
    "frame[\"Date\"] = pd.to_datetime(frame[\"DateTime\"]).dt.date\n",
    "frame[\"Time\"] = pd.to_datetime(frame[\"DateTime\"]).dt.time\n",
    "frame = frame.drop([\"DateTime\"], axis=1)\n",
    "\n",
    "frame.to_csv(path + \"/FITforecast_\" + area + \".csv\", encoding=\"shift_jis\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ForecastPV_Kansai</th>\n",
       "      <th>ForecastWind_Kansai</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83323</th>\n",
       "      <td>0</td>\n",
       "      <td>23300</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>21:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83324</th>\n",
       "      <td>0</td>\n",
       "      <td>23300</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83325</th>\n",
       "      <td>0</td>\n",
       "      <td>23300</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>22:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83326</th>\n",
       "      <td>0</td>\n",
       "      <td>23300</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83327</th>\n",
       "      <td>0</td>\n",
       "      <td>23300</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>23:30:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ForecastPV_Kansai  ForecastWind_Kansai        Date      Time\n",
       "83323                  0                23300  2020-12-31  21:30:00\n",
       "83324                  0                23300  2020-12-31  22:00:00\n",
       "83325                  0                23300  2020-12-31  22:30:00\n",
       "83326                  0                23300  2020-12-31  23:00:00\n",
       "83327                  0                23300  2020-12-31  23:30:00"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/kenotsu/Documents/master_thesis/Datasets/Master_thesis/Fit_actual_prediction/FITforecast_Kansai.csv\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_=[]\n",
    "frame = pd.DataFrame()\n",
    "area = \"Chugoku\"\n",
    "\n",
    "# Set the original common columns\n",
    "col_names = [\"Date\", \"Time\", \"ForecastPV_\"+area, \"ForecastWind_\"+area]\n",
    "# for file_path in allFiles:\n",
    "allFiles = sorted(glob.glob(path + area + \"/fit_tokurei1*.csv\")) \n",
    "\n",
    "for file_path in allFiles:\n",
    "    # Read csv\n",
    "    df = pd.read_csv(file_path, header=0, delimiter=\",\", names=col_names, skiprows=[0,1], usecols=[0,1,2,3])\n",
    "    list_.append(df)\n",
    "    \n",
    "# Concat all the csv file on the folder\n",
    "frame = pd.concat(list_, join='inner').reset_index(drop=True)\n",
    "\n",
    "# Adjust \"DateTime\"\n",
    "frame[\"DateTime\"] = DateTime[DateTime >= \"2018/01/01 00:00\"].reset_index(drop=True)\n",
    "frame[\"Date\"] = pd.to_datetime(frame[\"DateTime\"]).dt.date\n",
    "frame[\"Time\"] = pd.to_datetime(frame[\"DateTime\"]).dt.time\n",
    "frame = frame.drop([\"DateTime\"], axis=1)\n",
    "\n",
    "frame.to_csv(path + \"/FITforecast_\" + area + \".csv\", encoding=\"shift_jis\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>ForecastPV_Chugoku</th>\n",
       "      <th>ForecastWind_Chugoku</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52603</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>21:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>54121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52604</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>56205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52605</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>22:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>59203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52606</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>60213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52607</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>23:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>56329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date      Time  ForecastPV_Chugoku  ForecastWind_Chugoku\n",
       "52603  2020-12-31  21:30:00                   0                 54121\n",
       "52604  2020-12-31  22:00:00                   0                 56205\n",
       "52605  2020-12-31  22:30:00                   0                 59203\n",
       "52606  2020-12-31  23:00:00                   0                 60213\n",
       "52607  2020-12-31  23:30:00                   0                 56329"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/kenotsu/Documents/master_thesis/Datasets/Master_thesis/Fit_actual_prediction/FITforecast_Chugoku.csv\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_list_=[]\n",
    "wind_list_=[]\n",
    "frame = pd.DataFrame()\n",
    "area = \"Shikoku\"\n",
    "\n",
    "#For pv files\n",
    "# Set the original common columns\n",
    "col_names = [\"Date\", \"Time\", \"ForecastPV_\"+area]\n",
    "# for file_path in allFiles:\n",
    "allFiles = sorted(glob.glob(path + area + \"/pv*.csv\")) \n",
    "\n",
    "for file_path in allFiles:\n",
    "    # Read csv\n",
    "    df = pd.read_csv(file_path, header=0, delimiter=\",\", names=col_names, skiprows=[0,1], usecols=[0,1,2])\n",
    "    pv_list_.append(df)\n",
    "    \n",
    "# Concat all the csv file on the folder\n",
    "pv = pd.concat(pv_list_, join='inner').reset_index(drop=True)\n",
    "\n",
    "\n",
    "#For wind files\n",
    "# Set the original common columns\n",
    "col_names = [\"Date\", \"Time\", \"ForecastWind_\"+area]\n",
    "# for file_path in allFiles:\n",
    "allFiles = sorted(glob.glob(path + area + \"/wd*.csv\")) \n",
    "\n",
    "for file_path in allFiles:\n",
    "    # Read csv\n",
    "    df = pd.read_csv(file_path, header=0, delimiter=\",\", names=col_names, skiprows=[0,1], usecols=[0,1,2])\n",
    "    wind_list_.append(df)\n",
    "    \n",
    "# Concat all the csv file on the folder\n",
    "wind = pd.concat(wind_list_, join='inner').reset_index(drop=True)\n",
    "\n",
    "# Merge pv and wind\n",
    "frame = pd.merge(pv, wind, how=\"left\", on=[\"Date\", \"Time\"])\n",
    "frame = frame[frame.index <= 83327]\n",
    "\n",
    "# Adjust \"DateTime\"\n",
    "frame[\"DateTime\"] = DateTime[DateTime >= \"2016/04/01 00:00\"].reset_index(drop=True)\n",
    "frame[\"Date\"] = pd.to_datetime(frame[\"DateTime\"]).dt.date\n",
    "frame[\"Time\"] = pd.to_datetime(frame[\"DateTime\"]).dt.time\n",
    "frame = frame.drop([\"DateTime\"], axis=1)\n",
    "\n",
    "frame.to_csv(path + \"/FITforecast_\" + area + \".csv\", encoding=\"shift_jis\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>ForecastPV_Shikoku</th>\n",
       "      <th>ForecastWind_Shikoku</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83323</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>21:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83324</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83325</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>22:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83326</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>23:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83327</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>23:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date      Time  ForecastPV_Shikoku  ForecastWind_Shikoku\n",
       "83323  2020-12-31  21:30:00                 0.0                  52.0\n",
       "83324  2020-12-31  22:00:00                 0.0                  49.0\n",
       "83325  2020-12-31  22:30:00                 0.0                  47.0\n",
       "83326  2020-12-31  23:00:00                 0.0                  44.0\n",
       "83327  2020-12-31  23:30:00                 0.0                  43.0"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/kenotsu/Documents/master_thesis/Datasets/Master_thesis/Fit_actual_prediction/FITforecast_Shikoku.csv\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list=[]\n",
    "area = \"Kyushu\"\n",
    "\n",
    "# for file_path in allFiles:\n",
    "allFiles = sorted(glob.glob(path + area + '/*.xls')) \n",
    "\n",
    "# Read the sheat no.0 and 2 which are for the forecast information\n",
    "sheet_num = [0, 2]\n",
    "\n",
    "for file in allFiles:\n",
    "    for i in sheet_num:\n",
    "        df_sheet = pd.read_excel(file, sheet_name=i, skiprows=[0,1,2])\n",
    "        df_sheet = df_sheet.rename(columns={'Unnamed: 0': 'Date'})    \n",
    "        \n",
    "#         # Add \"Time\" Column\n",
    "#         df_sheet = df_sheet.reset_index(drop=True)\n",
    "        \n",
    "#         df_sheet[\"Time\"] = HH_time\n",
    "#         df_sheet = df_sheet.set_index(\"Time\")\n",
    "       # Make the dataframe for PV and Wind separately, and organize the format\n",
    "        if i == 0:\n",
    "            df_sheet_0 = df_sheet\n",
    "            df_sheet_0 = df_sheet_0.set_index(\"Date\")\n",
    "            df_sheet_0 = pd.DataFrame(df_sheet_0.stack())\n",
    "            df_sheet_0 = df_sheet_0.reset_index()\n",
    "            df_sheet_0 = df_sheet_0.rename(columns={'level_1': 'Time', 0: str(i)})    \n",
    "        else:\n",
    "            df_sheet_2 = df_sheet\n",
    "            df_sheet_2 = df_sheet_2.set_index(\"Date\")\n",
    "            df_sheet_2 = pd.DataFrame(df_sheet_2.stack())\n",
    "            df_sheet_2 = df_sheet_2.reset_index()\n",
    "            df_sheet_2 = df_sheet_2.rename(columns={'level_1': 'Time', 0: str(i)})  \n",
    "    # Concat all the sheet to make a file\n",
    "    df_file = pd.merge(df_sheet_0, df_sheet_2, how='left', on=['Date', 'Time'])\n",
    "    df_file = df_file.rename(columns={'0': 'Forecast_PV_Kyushu', '2':'Forecast_Wind_Kyushu'})\n",
    "    file_list.append(df_file)\n",
    "    \n",
    "# Merge all the csv file on the folder into a file\n",
    "frame = pd.concat(file_list, join='inner').reset_index(drop=True)\n",
    "\n",
    "# Adjust \"DateTime\"\n",
    "frame[\"DateTime\"] = DateTime[DateTime >= \"2016/04/01 00:00\"].reset_index(drop=True)\n",
    "frame[\"Date\"] = pd.to_datetime(frame[\"DateTime\"]).dt.date\n",
    "frame[\"Time\"] = pd.to_datetime(frame[\"DateTime\"]).dt.time\n",
    "frame = frame.drop([\"DateTime\"], axis=1)\n",
    "\n",
    "# There is a missing value on the column \"Forecast_Wind_Kyushu\" at 4:00 on 08/12/2019 --> fill with the interpolate method\n",
    "frame.interpolate(method='linear', inplace=True)\n",
    "\n",
    "frame.to_csv(path + \"/FITforecast_\" + area + \".csv\", encoding=\"shift_jis\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Forecast_PV_Kyushu</th>\n",
       "      <th>Forecast_Wind_Kyushu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>899.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>00:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12143.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12793.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>01:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14042.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14992.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time  Forecast_PV_Kyushu  Forecast_Wind_Kyushu\n",
       "0  2016-04-01  00:00:00                 0.0               899.550\n",
       "1  2016-04-01  00:30:00                 0.0             12143.925\n",
       "2  2016-04-01  01:00:00                 0.0             12793.600\n",
       "3  2016-04-01  01:30:00                 0.0             14042.975\n",
       "4  2016-04-01  02:00:00                 0.0             14992.500"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/kenotsu/Documents/master_thesis/Datasets/Master_thesis/Fit_actual_prediction/FITforecast_Kyushu.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_=[]\n",
    "frame = pd.DataFrame()\n",
    "area = \"Okinawa\"\n",
    "\n",
    "# Set the original common columns\n",
    "col_names = [\"DateTime\", \"ForecastPV_\"+area, \"ForecastWind_\"+area]\n",
    "# for file_path in allFiles:\n",
    "allFiles = sorted(glob.glob(path + area + \"/soutei_*.csv\")) \n",
    "\n",
    "for file_path in allFiles:\n",
    "    # Read csv\n",
    "    df = pd.read_csv(file_path, header=0, delimiter=\",\", names=col_names, usecols=[0,1,2])\n",
    "    list_.append(df)\n",
    "    \n",
    "# Concat all the csv file on the folder\n",
    "frame = pd.concat(list_, join='inner').reset_index(drop=True)\n",
    "\n",
    "# Adjust \"DateTime\"\n",
    "frame[\"DateTime\"] = DateTime[DateTime >= \"2016/04/01 00:00\"].reset_index(drop=True)\n",
    "frame[\"Date\"] = pd.to_datetime(frame[\"DateTime\"]).dt.date\n",
    "frame[\"Time\"] = pd.to_datetime(frame[\"DateTime\"]).dt.time\n",
    "frame = frame.drop([\"DateTime\"], axis=1)\n",
    "\n",
    "frame.to_csv(path + \"/FITforecast_\" + area + \".csv\", encoding=\"shift_jis\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ForecastPV_Okinawa</th>\n",
       "      <th>ForecastWind_Okinawa</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>02:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ForecastPV_Okinawa  ForecastWind_Okinawa        Date      Time\n",
       "0                 0.0                   1.2  2016-04-01  00:00:00\n",
       "1                 0.0                   1.1  2016-04-01  00:30:00\n",
       "2                 0.0                   1.1  2016-04-01  01:00:00\n",
       "3                 0.0                   1.0  2016-04-01  01:30:00\n",
       "4                 0.0                   0.8  2016-04-01  02:00:00"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/kenotsu/Documents/master_thesis/Datasets/Master_thesis/Fit_actual_prediction/FITforecast_Okinawa.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marge the data of Actual_generation(Tohoku_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual generation_dataset from 2016-08-01\n",
    "path ='/Users/kenotsu/Documents/master_thesis/Datasets/Master_thesis/使うかわからない軍/Actual_generation_5min/Actual_generation_5min_until_2020-4-14'\n",
    "allFiles = sorted(glob.glob(path + \"/*.csv\")) # 指定したフォルダーの全CSVファイルを変数に代入します\n",
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "col_names = [\"DATE\", \"TIME\", \"当日実績(5分間隔値)(万kW)\"]\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_, sep=',', header=36, encoding='shift_jis', names=col_names) # csvをデータフレームとして読み込む\n",
    "    list_.append(df)\n",
    "frame = pd.concat(list_, join='inner') # joinをinnerに指定\n",
    "frame.to_csv(\"/Users/kenotsu/Documents/master_thesis/Datasets/Master_thesis/使うかわからない軍/Actual_generation_5min\" + \"/Actual_generation1.csv\", encoding=\"shift_jis\", index=False)\n",
    "\n",
    "\n",
    "#Actual generation_dataset from 2020-04-14\n",
    "path ='/Users/kenotsu/Documents/master_thesis/Datasets/Master_thesis/使うかわからない軍/Actual_generation_5min/Actual_generation_5min_from_2020-4-15'\n",
    "allFiles = sorted(glob.glob(path + \"/*.csv\")) # 指定したフォルダーの全CSVファイルを変数に代入します\n",
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "col_names = [\"DATE\", \"TIME\", \"当日実績(5分間隔値)(万kW)\", \"太陽光発電実績(5分間隔値)(万kW)\", \"風力発電実績(5分間隔値)(万kW)\"]\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_, sep=',', header=44, encoding='shift_jis', names=col_names) # csvをデータフレームとして読み込む\n",
    "    list_.append(df)\n",
    "frame = pd.concat(list_, join='inner') # joinをinnerに指定\n",
    "frame.to_csv(\"/Users/kenotsu/Documents/master_thesis/Datasets/Master_thesis/使うかわからない軍/Actual_generation_5min\" + \"/Actual_generation2.csv\", encoding=\"shift_jis\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>当日実績(5分間隔値)(万kW)</th>\n",
       "      <th>太陽光発電実績(5分間隔値)(万kW)</th>\n",
       "      <th>風力発電実績(5分間隔値)(万kW)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020/4/15</td>\n",
       "      <td>0:00</td>\n",
       "      <td>802.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020/4/15</td>\n",
       "      <td>0:05</td>\n",
       "      <td>800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020/4/15</td>\n",
       "      <td>0:10</td>\n",
       "      <td>792.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020/4/15</td>\n",
       "      <td>0:15</td>\n",
       "      <td>793.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020/4/15</td>\n",
       "      <td>0:20</td>\n",
       "      <td>789.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE  TIME  当日実績(5分間隔値)(万kW)  太陽光発電実績(5分間隔値)(万kW)  風力発電実績(5分間隔値)(万kW)\n",
       "0  2020/4/15  0:00             802.0                  1.0                57.0\n",
       "1  2020/4/15  0:05             800.0                  1.0                59.0\n",
       "2  2020/4/15  0:10             792.0                  1.0                60.0\n",
       "3  2020/4/15  0:15             793.0                  1.0                61.0\n",
       "4  2020/4/15  0:20             789.0                  1.0                61.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make HH_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read df_intra and adjustment\n",
    "df_intra = pd.read_csv('/Users/kenotsu/Documents/master_thesis/Datasets/Master_thesis/im_trade_summary_2016.csv', sep=',', header=0, encoding='shift_jis')\n",
    "df_intra = df_intra.rename(columns={'年月日': 'Date', \n",
    "                                    '時刻コード': 'HH',\n",
    "                                    '始値（円/kWh）': 'Open',\n",
    "                                    '高値（円/kWh）': 'High',\n",
    "                                    '安値（円/kWh）': 'Low',\n",
    "                                    '終値（円/kWh）': 'Close',\n",
    "                                    '平均（円/kWh）': 'Average',\n",
    "                                    '約定量合計（MWh/h）': 'Volume(MWh/h)',\n",
    "                                    '約定件数': 'Volume(Tick count)'})\n",
    "df_intra[\"Date\"] = pd.to_datetime(df_intra[\"Date\"])\n",
    "\n",
    "# Read df_intra and adjustment\n",
    "df_actual_generation_Tohoku = pd.read_csv('/Users/kenotsu/Documents/master_thesis/Datasets/Master_thesis/使うかわからない軍/Actual_generation_5min/Actual_generation1.csv', sep=',', header=0, encoding='cp932')\n",
    "df_actual_generation_Tohoku = df_actual_generation_Tohoku.rename(columns={'DATE': 'Date', 'TIME': 'Time',\n",
    "    '太陽光発電実績(5分間隔値)(万kW)': 'gen_Solar(mkW)', '当日実績(5分間隔値)(万kW)': 'gen_all(mkW)', '風力発電実績(5分間隔値)(万kW)': 'gen_Wind(mkW)'\n",
    "})\n",
    "df_actual_generation_Tohoku[\"DateTime\"] = pd.to_datetime(df_actual_generation_Tohoku[\"Date\"] + \" \" + df_actual_generation_Tohoku[\"Time\"])\n",
    "df_actual_generation_Tohoku = df_actual_generation_Tohoku.groupby(pd.Grouper(key=\"DateTime\", freq='30min')).sum().reset_index()\n",
    "df_actual_generation_Tohoku[\"Time\"] = pd.to_datetime(df_actual_generation_Tohoku[\"DateTime\"]).dt.time\n",
    "df_actual_generation_Tohoku[\"Date\"] = pd.to_datetime(df_actual_generation_Tohoku[\"DateTime\"]).dt.date\n",
    "\n",
    "# Make HH_table\n",
    "HH_table = pd.DataFrame(df_intra[\"HH\"])\n",
    "HH_table = HH_table.drop_duplicates()\n",
    "time = df_actual_generation_Tohoku[\"Time\"]\n",
    "time = pd.DataFrame(time)\n",
    "time = time.drop_duplicates()\n",
    "HH_table[\"Time\"] = time.astype(\"str\")\n",
    "HH_table.to_csv(\"/Users/kenotsu/Documents/master_thesis/Datasets/Master_thesis\" + \"/HH_table.csv\", encoding=\"shift_jis\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HH</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>01:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>02:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>03:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>04:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>05:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>06:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>07:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>08:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>09:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>10:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>11:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>12:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>13:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>14:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>14:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>15:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>16:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>17:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>18:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>19:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>20:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>21:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>22:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>23:30:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    HH      Time\n",
       "0    1  00:00:00\n",
       "1    2  00:30:00\n",
       "2    3  01:00:00\n",
       "3    4  01:30:00\n",
       "4    5  02:00:00\n",
       "5    6  02:30:00\n",
       "6    7  03:00:00\n",
       "7    8  03:30:00\n",
       "8    9  04:00:00\n",
       "9   10  04:30:00\n",
       "10  11  05:00:00\n",
       "11  12  05:30:00\n",
       "12  13  06:00:00\n",
       "13  14  06:30:00\n",
       "14  15  07:00:00\n",
       "15  16  07:30:00\n",
       "16  17  08:00:00\n",
       "17  18  08:30:00\n",
       "18  19  09:00:00\n",
       "19  20  09:30:00\n",
       "20  21  10:00:00\n",
       "21  22  10:30:00\n",
       "22  23  11:00:00\n",
       "23  24  11:30:00\n",
       "24  25  12:00:00\n",
       "25  26  12:30:00\n",
       "26  27  13:00:00\n",
       "27  28  13:30:00\n",
       "28  29  14:00:00\n",
       "29  30  14:30:00\n",
       "30  31  15:00:00\n",
       "31  32  15:30:00\n",
       "32  33  16:00:00\n",
       "33  34  16:30:00\n",
       "34  35  17:00:00\n",
       "35  36  17:30:00\n",
       "36  37  18:00:00\n",
       "37  38  18:30:00\n",
       "38  39  19:00:00\n",
       "39  40  19:30:00\n",
       "40  41  20:00:00\n",
       "41  42  20:30:00\n",
       "42  43  21:00:00\n",
       "43  44  21:30:00\n",
       "44  45  22:00:00\n",
       "45  46  22:30:00\n",
       "46  47  23:00:00\n",
       "47  48  23:30:00"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HH_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokyo, Hokkaido and Okinawa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read all the weather data\n",
    "path ='/Users/kenotsu/Documents/master_thesis/Datasets/Master_thesis/使うかわからない軍/Weather'\n",
    "Areas = [\"Tokyo\", \"Hokkaido\", \"Okinawa\"]\n",
    "\n",
    "for area in Areas:\n",
    "\n",
    "    frame = pd.DataFrame()\n",
    "    list_ = []\n",
    "    col_names = [\"DateTime\",\n",
    "                 \"Temp_\" + area, \"Temp_Qual_\" + area, \"Temp_Num_\" + area, \n",
    "                 \"SunLight(Time)_\" + area, \"SunLight(Time)_None_\" + area, \"SunLight(Time)_Qual_\" + area, \"SunLight(Time)_Num_\" + area, \n",
    "                 \"WindSpeed(m/s)_\" + area, \"WindSpeed(m/s)_Qual_\" + area, \"WindDirection_\" + area, \"WindDirection_Qual_\" + area, \n",
    "                 \"WindSpeed(m/s)_Num_\" + area, \"SunLight(MJ/㎡)_\" + area, \"SunLight(MJ/㎡)_Qual_\" + area, \"SunLight(MJ/㎡)_Num_\" + area, \n",
    "                 ]\n",
    "\n",
    "    allFiles_ = sorted(glob.glob(path + \"/\" + area + \"/*.csv\"))\n",
    "    for file_ in allFiles_:\n",
    "        df = pd.read_csv(file_, sep=',', header=0, encoding='cp932', engine=\"python\", names=col_names, skiprows=[0,1,2,3,4,5]) # csvをデータフレームとして読み込む\n",
    "        list_.append(df)\n",
    "    frame = pd.concat(list_, join='inner') # joinをinnerに指定\n",
    "\n",
    "    # Adjust \"DateTime\" column\n",
    "    frame[\"DateTime\"] = frame[\"DateTime\"].shift(1)\n",
    "    frame[\"DateTime\"] = frame[\"DateTime\"].fillna(\"2016/4/1 00:00:00\")\n",
    "    frame.to_csv(path + \"/Weather_\" + area + \".csv\", encoding=\"cp932\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41664, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather_Tokyo = pd.read_csv(path + '/Weather_Tokyo.csv', sep=',', header=0, encoding='cp932')\n",
    "df_weather_Tokyo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tohoku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Read all the weather data in Tohoku area\n",
    "path ='/Users/kenotsu/Documents/Datasets/Master_thesis/Weather'\n",
    "frame = pd.DataFrame()\n",
    "# col_names = [\"Date\",\n",
    "#              \"Temp\", \"Temp_Qual\", \"Temp_Num\", \n",
    "#              \"SunLight(Time)\", \"SunLight(Time)_None\", \"SunLight(Time)_Qual\", \"SunLight(Time)_Num\", \n",
    "#              \"WindSpeed(m/s)\", \"WindSpeed(m/s)_Qual\", \"WindDirection\", \"WindDirection_Qual\", \"WindSpeed(m/s)_Num\", \n",
    "#              \"SunLight(MJ/㎡)\", \"SunLight(MJ/㎡)_Qual\", \"SunLight(MJ/㎡)_Num\", \n",
    "#              ]\n",
    "\n",
    "#Weather data in Aomori\n",
    "list_Aomori = []\n",
    "col_names = [\"Date\",\n",
    "             \"Temp_Ao\", \"Temp_Qual_Ao\", \"Temp_Num_Ao\", \n",
    "             \"SunLight(Time)_Ao\", \"SunLight(Time)_None_Ao\", \"SunLight(Time)_Qual_Ao\", \"SunLight(Time)_Num_Ao\", \n",
    "             \"WindSpeed(m/s)_Ao\", \"WindSpeed(m/s)_Qual_Ao\", \"WindDirection_Ao\", \"WindDirection_Qual_Ao\", \"WindSpeed(m/s)_Num_Ao\", \n",
    "             \"SunLight(MJ/㎡)_Ao\", \"SunLight(MJ/㎡)_Qual_Ao\", \"SunLight(MJ/㎡)_Num_Ao\", \n",
    "             ]\n",
    "allFiles_Aomori = sorted(glob.glob(path + \"/Aomori_*.csv\"))\n",
    "for file_Aomori in allFiles_Aomori:\n",
    "    df = pd.read_csv(file_Aomori, sep=',', header=0, encoding='cp932', engine=\"python\", names=col_names, skiprows=[0,1,2,3,4,5]) # csvをデータフレームとして読み込む\n",
    "    list_Aomori.append(df)\n",
    "frame = pd.concat(list_Aomori, join='inner') # joinをinnerに指定\n",
    "frame.to_csv('/Users/kenotsu/Documents/Datasets/Master_thesis/Weather' + \"/Weather_Aomori.csv\", encoding=\"cp932\", index=False)\n",
    "\n",
    "#Weather data in Akita\n",
    "list_Akita = []\n",
    "col_names = [\"Date\",\n",
    "             \"Temp_Aki\", \"Temp_Qual_Aki\", \"Temp_Num_Aki\", \n",
    "             \"SunLight(Time)_Aki\", \"SunLight(Time)_None_Aki\", \"SunLight(Time)_Qual_Aki\", \"SunLight(Time)_Num_Aki\", \n",
    "             \"WindSpeed(m/s)_Aki\", \"WindSpeed(m/s)_Qual_Aki\", \"WindDirection_Aki\", \"WindDirection_Qual_Aki\", \"WindSpeed(m/s)_Num_Aki\", \n",
    "             \"SunLight(MJ/㎡)_Aki\", \"SunLight(MJ/㎡)_Qual_Aki\", \"SunLight(MJ/㎡)_Num_Aki\", \n",
    "             ]\n",
    "allFiles_Akita = sorted(glob.glob(path + \"/Akita_*.csv\"))\n",
    "for file_Akita in allFiles_Akita:\n",
    "    df = pd.read_csv(file_Akita, sep=',', header=0, encoding='cp932', engine=\"python\", names=col_names, skiprows=[0,1,2,3,4,5]) # csvをデータフレームとして読み込む\n",
    "    list_Akita.append(df)\n",
    "frame = pd.concat(list_Akita, join='inner') # joinをinnerに指定\n",
    "frame.to_csv('/Users/kenotsu/Documents/Datasets/Master_thesis/Weather' + \"/Weather_Akita.csv\", encoding=\"cp932\", index=False)\n",
    "\n",
    "#Weather data in Morioka\n",
    "list_Morioka = []\n",
    "col_names = [\"Date\",\n",
    "             \"Temp_Mo\", \"Temp_Qual_Mo\", \"Temp_Num_Mo\", \n",
    "             \"SunLight(Time)_Mo\", \"SunLight(Time)_None_Mo\", \"SunLight(Time)_Qual_Mo\", \"SunLight(Time)_Num_Mo\", \n",
    "             \"WindSpeed(m/s)_Mo\", \"WindSpeed(m/s)_Qual_Mo\", \"WindDirection_Mo\", \"WindDirection_Qual_Mo\", \"WindSpeed(m/s)_Num_Mo\", \n",
    "             \"SunLight(MJ/㎡)_Mo\", \"SunLight(MJ/㎡)_Qual_Mo\", \"SunLight(MJ/㎡)_Num_Mo\", \n",
    "             ]\n",
    "allFiles_Morioka = sorted(glob.glob(path + \"/Morioka_*.csv\"))\n",
    "for file_Morioka in allFiles_Morioka:\n",
    "    df = pd.read_csv(file_Morioka, sep=',', header=0, encoding='cp932', engine=\"python\", names=col_names, skiprows=[0,1,2,3,4,5]) # csvをデータフレームとして読み込む\n",
    "    list_Morioka.append(df)\n",
    "frame = pd.concat(list_Morioka, join='inner') # joinをinnerに指定\n",
    "frame.to_csv('/Users/kenotsu/Documents/Datasets/Master_thesis/Weather' + \"/Weather_Morioka.csv\", encoding=\"cp932\", index=False)\n",
    "\n",
    "#Weather data in Yamagata\n",
    "list_Yamagata = []\n",
    "col_names = [\"Date\",\n",
    "             \"Temp_Ya\", \"Temp_Qual_Ya\", \"Temp_Num_Ya\", \n",
    "             \"SunLight(Time)_Ya\", \"SunLight(Time)_None_Ya\", \"SunLight(Time)_Qual_Ya\", \"SunLight(Time)_Num_Ya\", \n",
    "             \"WindSpeed(m/s)_Ya\", \"WindSpeed(m/s)_Qual_Ya\", \"WindDirection_Ya\", \"WindDirection_Qual_Ya\", \"WindSpeed(m/s)_Num_Ya\", \n",
    "             \"SunLight(MJ/㎡)_Ya\", \"SunLight(MJ/㎡)_Qual_Ya\", \"SunLight(MJ/㎡)_Num_Ya\", \n",
    "             ]\n",
    "allFiles_Yamagata = sorted(glob.glob(path + \"/Yamagata_*.csv\"))\n",
    "for file_Yamagata in allFiles_Yamagata:\n",
    "    df = pd.read_csv(file_Yamagata, sep=',', header=0, encoding='cp932', engine=\"python\", names=col_names, skiprows=[0,1,2,3,4,5]) # csvをデータフレームとして読み込む\n",
    "    list_Yamagata.append(df)\n",
    "frame = pd.concat(list_Yamagata, join='inner') # joinをinnerに指定\n",
    "frame.to_csv('/Users/kenotsu/Documents/Datasets/Master_thesis/Weather' + \"/Weather_Yamagata.csv\", encoding=\"cp932\", index=False)\n",
    "\n",
    "#Weather data in Sendai\n",
    "list_Sendai = []\n",
    "col_names = [\"Date\",\n",
    "             \"Temp_Se\", \"Temp_Qual_Se\", \"Temp_Num_Se\", \n",
    "             \"SunLight(Time)_Se\", \"SunLight(Time)_None_Se\", \"SunLight(Time)_Qual_Se\", \"SunLight(Time)_Num_Se\", \n",
    "             \"WindSpeed(m/s)_Se\", \"WindSpeed(m/s)_Qual_Se\", \"WindDirection_Se\", \"WindDirection_Qual_Se\", \"WindSpeed(m/s)_Num_Se\", \n",
    "             \"SunLight(MJ/㎡)_Se\", \"SunLight(MJ/㎡)_Qual_Se\", \"SunLight(MJ/㎡)_Num_Se\", \n",
    "             ]\n",
    "allFiles_Sendai = sorted(glob.glob(path + \"/Sendai_*.csv\"))\n",
    "for file_Sendai in allFiles_Sendai:\n",
    "    df = pd.read_csv(file_Sendai, sep=',', header=0, encoding='cp932', engine=\"python\", names=col_names, skiprows=[0,1,2,3,4,5]) # csvをデータフレームとして読み込む\n",
    "    list_Sendai.append(df)\n",
    "frame = pd.concat(list_Sendai, join='inner') # joinをinnerに指定\n",
    "frame.to_csv('/Users/kenotsu/Documents/Datasets/Master_thesis/Weather' + \"/Weather_Sendai.csv\", encoding=\"cp932\", index=False)\n",
    "\n",
    "#Weather data in Fukushima\n",
    "list_Fukushima = []\n",
    "col_names = [\"Date\",\n",
    "             \"Temp_Fu\", \"Temp_Qual_Fu\", \"Temp_Num_Fu\", \n",
    "             \"SunLight(Time)_Fu\", \"SunLight(Time)_None_Fu\", \"SunLight(Time)_Qual_Fu\", \"SunLight(Time)_Num_Fu\", \n",
    "             \"WindSpeed(m/s)_Fu\", \"WindSpeed(m/s)_Qual_Fu\", \"WindDirection_Fu\", \"WindDirection_Qual_Fu\", \"WindSpeed(m/s)_Num_Fu\", \n",
    "             \"SunLight(MJ/㎡)_Fu\", \"SunLight(MJ/㎡)_Qual_Fu\", \"SunLight(MJ/㎡)_Num_Fu\", \n",
    "             ]\n",
    "allFiles_Fukushima = sorted(glob.glob(path + \"/Fukushima_*.csv\"))\n",
    "for file_Fukushima in allFiles_Fukushima:\n",
    "    df = pd.read_csv(file_Fukushima, sep=',', header=0, encoding='cp932', engine=\"python\", names=col_names, skiprows=[0,1,2,3,4,5]) # csvをデータフレームとして読み込む\n",
    "    list_Fukushima.append(df)\n",
    "frame = pd.concat(list_Fukushima, join='inner') # joinをinnerに指定\n",
    "frame.to_csv('/Users/kenotsu/Documents/Datasets/Master_thesis/Weather' + \"/Weather_Fukushima.csv\", encoding=\"cp932\", index=False)\n",
    "\n",
    "#Weather data in Niigata\n",
    "list_Niigata = []\n",
    "col_names = [\"Date\",\n",
    "             \"Temp_Ni\", \"Temp_Qual_Ni\", \"Temp_Num_Ni\", \n",
    "             \"SunLight(Time)_Ni\", \"SunLight(Time)_None_Ni\", \"SunLight(Time)_Qual_Ni\", \"SunLight(Time)_Num_Ni\", \n",
    "             \"WindSpeed(m/s)_Ni\", \"WindSpeed(m/s)_Qual_Ni\", \"WindDirection_Ni\", \"WindDirection_Qual_Ni\", \"WindSpeed(m/s)_Num_Ni\", \n",
    "             \"SunLight(MJ/㎡)_Ni\", \"SunLight(MJ/㎡)_Qual_Ni\", \"SunLight(MJ/㎡)_Num_Ni\", \n",
    "             ]\n",
    "allFiles_Niigata = sorted(glob.glob(path + \"/Niigata_*.csv\"))\n",
    "for file_Niigata in allFiles_Niigata:\n",
    "    df = pd.read_csv(file_Niigata, sep=',', header=0, encoding='cp932', engine=\"python\", names=col_names, skiprows=[0,1,2,3,4,5]) # csvをデータフレームとして読み込む\n",
    "    list_Niigata.append(df)\n",
    "frame = pd.concat(list_Niigata, join='inner') # joinをinnerに指定\n",
    "frame.to_csv('/Users/kenotsu/Documents/Datasets/Master_thesis/Weather' + \"/Weather_Niigata.csv\", encoding=\"cp932\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記ループはもう少し短縮化できるはず(とくに列名の部分)\n",
    "\n",
    "for col in col_names:\n",
    "       if col  + \"_a\"\n",
    "       col\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "201px",
    "width": "439px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "176px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
